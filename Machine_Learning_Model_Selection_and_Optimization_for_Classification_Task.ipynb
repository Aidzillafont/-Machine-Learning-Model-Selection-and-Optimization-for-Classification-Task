{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aidzillafont/-Machine-Learning-Model-Selection-and-Optimization-for-Classification-Task/blob/main/Machine_Learning_Model_Selection_and_Optimization_for_Classification_Task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WfrCFmLHxYu"
      },
      "source": [
        "\n",
        "# Objective\n",
        "\n",
        "The Boolean satisfiability (SAT) problem consists in determining whether a Boolean formula F is satisfiable or not. F is represented by a pair (X, C), where X is a set of Boolean variables and C is a set of clauses in Conjunctive Normal Form (CNF). Each clause is a disjunction of literals (a variable or its negation). This problem is one of the most widely studied combinatorial problems in computer science. It is the classic NP-complete problem. Over the past number of decades, a significant amount of research work has focused on solving SAT problems with both complete and incomplete solvers.\n",
        "\n",
        "Recent advances in supervised learning have provided powerful techniques for classifying problems. In this project, we see the SAT problem as a classification problem. Given a Boolean formula (represented by a vector of features), we are asked to predict if it is satisfiable or not.\n",
        "\n",
        "In this project, we represent SAT problems with a vector of 327 features with general information about the problem, e.g., number of variables, number of clauses, fraction of horn clauses in the problem, etc. There is no need to understand the features to be able to complete the assignment.\n",
        "\n",
        "The dataset is available at:\n",
        "https://github.com/andvise/DataAnalyticsDatasets/blob/main/dm_assignment2/sat_dataset_train.csv\n",
        "\n",
        "This is original unpublished data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oav9G1WSJ1nH"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "DE0kM0QsJ1En",
        "outputId": "1c6f5555-27cd-4caa-ca3f-cc031aba2c4d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5ea149bf-3efd-4bfa-aae2-9000bbbe6de7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c</th>\n",
              "      <th>v</th>\n",
              "      <th>clauses_vars_ratio</th>\n",
              "      <th>vars_clauses_ratio</th>\n",
              "      <th>vcg_var_mean</th>\n",
              "      <th>vcg_var_coeff</th>\n",
              "      <th>vcg_var_min</th>\n",
              "      <th>vcg_var_max</th>\n",
              "      <th>vcg_var_entropy</th>\n",
              "      <th>vcg_clause_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>rwh_0_max</th>\n",
              "      <th>rwh_1_mean</th>\n",
              "      <th>rwh_1_coeff</th>\n",
              "      <th>rwh_1_min</th>\n",
              "      <th>rwh_1_max</th>\n",
              "      <th>rwh_2_mean</th>\n",
              "      <th>rwh_2_coeff</th>\n",
              "      <th>rwh_2_min</th>\n",
              "      <th>rwh_2_max</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>420</td>\n",
              "      <td>10</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>0.023810</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>...</td>\n",
              "      <td>78750.0</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.875000e-06</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>2.385082e-21</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.385082e-21</td>\n",
              "      <td>2.385082e-21</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>230</td>\n",
              "      <td>20</td>\n",
              "      <td>11.500000</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.137826</td>\n",
              "      <td>0.089281</td>\n",
              "      <td>0.117391</td>\n",
              "      <td>0.160870</td>\n",
              "      <td>2.180946</td>\n",
              "      <td>0.137826</td>\n",
              "      <td>...</td>\n",
              "      <td>6646875.0</td>\n",
              "      <td>17433.722184</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.981244e-12</td>\n",
              "      <td>34867.444369</td>\n",
              "      <td>1.727721e+04</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.358551e-53</td>\n",
              "      <td>3.455442e+04</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>240</td>\n",
              "      <td>16</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>...</td>\n",
              "      <td>500000.0</td>\n",
              "      <td>1525.878932</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.525879e+03</td>\n",
              "      <td>1525.878932</td>\n",
              "      <td>1.525879e+03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.525879e+03</td>\n",
              "      <td>1.525879e+03</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>424</td>\n",
              "      <td>30</td>\n",
              "      <td>14.133333</td>\n",
              "      <td>0.070755</td>\n",
              "      <td>0.226415</td>\n",
              "      <td>0.485913</td>\n",
              "      <td>0.056604</td>\n",
              "      <td>0.452830</td>\n",
              "      <td>2.220088</td>\n",
              "      <td>0.226415</td>\n",
              "      <td>...</td>\n",
              "      <td>87500.0</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.535723e-14</td>\n",
              "      <td>0.000245</td>\n",
              "      <td>8.218628e-07</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.499676e-61</td>\n",
              "      <td>1.643726e-06</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>162</td>\n",
              "      <td>19</td>\n",
              "      <td>8.526316</td>\n",
              "      <td>0.117284</td>\n",
              "      <td>0.139701</td>\n",
              "      <td>0.121821</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.185185</td>\n",
              "      <td>1.940843</td>\n",
              "      <td>0.139701</td>\n",
              "      <td>...</td>\n",
              "      <td>5859400.0</td>\n",
              "      <td>16591.494310</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.912726e-42</td>\n",
              "      <td>33182.988621</td>\n",
              "      <td>1.665903e+04</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.331807e+04</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 328 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ea149bf-3efd-4bfa-aae2-9000bbbe6de7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ea149bf-3efd-4bfa-aae2-9000bbbe6de7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ea149bf-3efd-4bfa-aae2-9000bbbe6de7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     c   v  clauses_vars_ratio  vars_clauses_ratio  vcg_var_mean  \\\n",
              "0  420  10           42.000000            0.023810      0.600000   \n",
              "1  230  20           11.500000            0.086957      0.137826   \n",
              "2  240  16           15.000000            0.066667      0.300000   \n",
              "3  424  30           14.133333            0.070755      0.226415   \n",
              "4  162  19            8.526316            0.117284      0.139701   \n",
              "\n",
              "   vcg_var_coeff  vcg_var_min  vcg_var_max  vcg_var_entropy  vcg_clause_mean  \\\n",
              "0       0.000000     0.600000     0.600000         0.000000         0.600000   \n",
              "1       0.089281     0.117391     0.160870         2.180946         0.137826   \n",
              "2       0.000000     0.300000     0.300000         0.000000         0.300000   \n",
              "3       0.485913     0.056604     0.452830         2.220088         0.226415   \n",
              "4       0.121821     0.111111     0.185185         1.940843         0.139701   \n",
              "\n",
              "   ...  rwh_0_max    rwh_1_mean  rwh_1_coeff     rwh_1_min     rwh_1_max  \\\n",
              "0  ...    78750.0      0.000008          0.0  7.875000e-06      0.000008   \n",
              "1  ...  6646875.0  17433.722184          1.0  2.981244e-12  34867.444369   \n",
              "2  ...   500000.0   1525.878932          0.0  1.525879e+03   1525.878932   \n",
              "3  ...    87500.0      0.000122          1.0  6.535723e-14      0.000245   \n",
              "4  ...  5859400.0  16591.494310          1.0  6.912726e-42  33182.988621   \n",
              "\n",
              "     rwh_2_mean  rwh_2_coeff     rwh_2_min     rwh_2_max  target  \n",
              "0  2.385082e-21          0.0  2.385082e-21  2.385082e-21       1  \n",
              "1  1.727721e+04          1.0  1.358551e-53  3.455442e+04       0  \n",
              "2  1.525879e+03          0.0  1.525879e+03  1.525879e+03       1  \n",
              "3  8.218628e-07          1.0  1.499676e-61  1.643726e-06       0  \n",
              "4  1.665903e+04          1.0  0.000000e+00  3.331807e+04       1  \n",
              "\n",
              "[5 rows x 328 columns]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"https://github.com/andvise/DataAnalyticsDatasets/blob/6d5738101d173b97c565f143f945dedb9c42a400/dm_assignment2/sat_dataset_train.csv?raw=true\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOqpQTS-K8EN",
        "outputId": "5448e26c-6b45-4f25-af27-303c6ebe5aa7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "c                       int64\n",
              "v                       int64\n",
              "clauses_vars_ratio    float64\n",
              "vars_clauses_ratio    float64\n",
              "vcg_var_mean          float64\n",
              "                       ...   \n",
              "rwh_2_mean            float64\n",
              "rwh_2_coeff           float64\n",
              "rwh_2_min             float64\n",
              "rwh_2_max             float64\n",
              "target                  int64\n",
              "Length: 328, dtype: object"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8MCvTYTKw4Q",
        "outputId": "f2e2952d-fbed-480b-c869-bfa7fac3ad4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    976\n",
              "0    953\n",
              "Name: target, dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['target'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5q7WUjGdyemS"
      },
      "source": [
        "### Feature Selection and Sparsity Evaluation\n",
        "\n",
        "1. Select the features by considering all columns except the target column, and assign the target column to the label variable.\n",
        "2. Evaluate the sparsity of the entire feature set. Since it contains 31% zeros, the dataset is not considered sparse.\n",
        "3. Create a train-test split with a random state of 6405 and a test size of 30%.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEjqR2xLKjec",
        "outputId": "af308e0f-487b-4ddf-de53-20d0ea371aee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ratio of sparse points to total data points in our feature set is:  0.31475800711179597\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "features = list(df.columns)\n",
        "features.pop()\n",
        "labels = ['target']\n",
        "\n",
        "X,y = df[features], df[labels]\n",
        "\n",
        "print('Ratio of sparse points to total data points in our feature set is: ', (X.to_numpy() == 0).mean())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y.values.ravel(), test_size=0.30, random_state=6405)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iU7MCBDYzqHw"
      },
      "source": [
        "### Replace infs with nans Custom Transformer\n",
        "Since there is a number of infs in our feature set we will replace these with nans and then impute these values later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_vdoYWJu6VK"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# a custom transformation for my pipeline changes inf and -inf to np.nan for simple imputer\n",
        "class RemoveInfs(BaseEstimator, TransformerMixin) : \n",
        "     def __init__(self) : \n",
        "          pass\n",
        "\n",
        "     def fit(self, X, y=None) : \n",
        "          return self\n",
        "\n",
        "     def transform(self, X) : \n",
        "          X = X.replace([np.inf, -np.inf], np.nan)\n",
        "          return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTvkBPQvITf-"
      },
      "source": [
        "# Tasks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7N7fg7805ep"
      },
      "source": [
        "## Basic models and evaluation\n",
        "\n",
        "Using Scikit-learn, train and evaluate K-NN and decision tree classifiers using 70% of the dataset from training and 30% for testing. We just want to get an idea of the dataset. Compare the results of both classifiers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CEmnzwSz9er"
      },
      "source": [
        "### Pipeline Overview\n",
        "\n",
        "1. The fundamental pipeline incorporates a custom transformation, `RemoveInf()`, which replaces infinite values with NaNs.\n",
        "2. Next, the `SimpleImputer()` is used to replace NaNs with the mean value of the corresponding feature.\n",
        "3. Lastly, the imputed data is passed to the chosen estimator, and the train/test performance is evaluated.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zl0VXO0YH1nG",
        "outputId": "0950974f-0a70-4da8-8bba-ae0138ae0378"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|**********KNN**********|\n",
            " Best Score Train: \n",
            " 0.9081481481481481 \n",
            "Best Score: \n",
            " 0.8911917098445595 \n",
            "\n",
            "|**********Tree**********|\n",
            " Best Score Train: \n",
            " 1.0 \n",
            "Best Score: \n",
            " 0.9792746113989638 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#load pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "#load some preprocessing steps \n",
        "#Note earlier we identified the matrixs as having a low sparsity ratio 0.3 so will use PCA\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#loading models \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "#load our cross validator\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "knn_pipe = Pipeline([('inf_b_gone',RemoveInfs()), ('simp', SimpleImputer()), ('knn', KNeighborsClassifier())])\n",
        "knn_pipe.fit(X_train, y_train)\n",
        "\n",
        "tree_pipe = Pipeline([('inf_b_gone',RemoveInfs()), ('simp', SimpleImputer()), ('tree', DecisionTreeClassifier())])\n",
        "tree_pipe.fit(X_train, y_train)\n",
        "\n",
        "#How did these preforme on our train and test sets\n",
        "print('|**********KNN**********|\\n', \n",
        "      'Best Score Train: \\n', knn_pipe.score(X_train, y_train), '\\n'\n",
        "      'Best Score: \\n', knn_pipe.score(X_test, y_test), '\\n',)\n",
        "\n",
        "print('|**********Tree**********|\\n', \n",
        "      'Best Score Train: \\n', tree_pipe.score(X_train, y_train), '\\n'\n",
        "      'Best Score: \\n', tree_pipe.score(X_test, y_test), '\\n',)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if1xVcPa8aQR"
      },
      "source": [
        "### Observations on Results\n",
        "\n",
        "**K-Nearest Neighbors (KNN):** The training performance is similar to the test performance. It is likely that scaling the features could further improve the model's performance.\n",
        "\n",
        "**Decision Tree:** The training score is perfect, while the test score is 2% lower, which suggests potential overfitting. Consider tuning the model to mitigate overfitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zADpr0f8IcGL"
      },
      "source": [
        "## Robust evaluation\n",
        "\n",
        "In this section, we are interested in more rigorous techniques by implementing more sophisticated methods, for instance:\n",
        "* Hold-out and cross-validation.\n",
        "* Hyper-parameter tuning.\n",
        "* Feature reduction.\n",
        "* Feature normalisation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7rVlyT61BRD"
      },
      "source": [
        "### Enhanced Pipeline Explanation\n",
        "\n",
        "The original pipeline has been extended with the addition of a Standard Scaler and PCA, chosen for the following reasons:\n",
        "\n",
        "1. **Standard Scaler:** Ensures that no feature has a bias due to scale of values. This is particularly important for KNN, as this type of model is sensitive to non-scaled values.\n",
        "2. **PCA:** Given that the feature set is not overly sparse and there are 328 features compared to 2000 cases, some form of feature reduction is necessary to address the curse of dimensionality.\n",
        "\n",
        "*Note:* For PCA, it is assumed that the variables are linearly related, orthogonal, and that variance is a measure of the 'informativeness' of a variable. Additionally, the choice of imputation is somewhat arbitrary. In practice, domain experts should be consulted for advice on handling missing values in the dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE6XclOx3WS2"
      },
      "source": [
        "### Parameter Selection for Cross-Validation\n",
        "\n",
        "#### Preprocessing\n",
        "- The imputer is set to use the 'mean' strategy. Although this is the default value, the line of code is included for clarity.\n",
        "- The PCA searches over a range of options for the number of components to retain. The 'mle' option utilizes Minka's MLE to estimate the optimal number of components. Additionally, 20, 50, and 100 components are considered as they provide a sufficiently small ratio of samples to features (at least 10 samples per feature).\n",
        "\n",
        "#### K-Nearest Neighbors (KNN)\n",
        "- The search for the optimal number of neighbors includes odd numbers up to 11 to prevent ties during voting.\n",
        "\n",
        "#### Decision Tree\n",
        "- Both Gini impurity and entropy are evaluated as criteria for splitting nodes, exploring all possibilities in this regard.\n",
        "- Powers of 2 are considered for the maximum tree depth (2^4, 2^5, 2^6). Limiting tree depth helps to prevent overfitting and improve generalization, as deeper trees tend to overfit and generalize less effectively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvBZH6ilInsA",
        "outputId": "21ffaa3e-d942-46cd-f798-37a8631bc216"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "|**********KNN**********|\n",
            " Best Params: \n",
            " {'knn__n_neighbors': 1, 'pca__n_components': 50, 'simp__strategy': 'mean'} \n",
            " Best Score: \n",
            " 0.922962962962963 \n",
            "\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "|**********Tree**********|\n",
            " Best Params: \n",
            " {'pca__n_components': 50, 'simp__strategy': 'mean', 'tree__criterion': 'entropy', 'tree__max_depth': 64} \n",
            " Best Score: \n",
            " 0.9007407407407408 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Lets rebuild our piplines adding a standardscaler and some feature reduction\n",
        "#Note earlier we identified the matrixs as having a low sparsity ratio 0.3\n",
        "#so I will use PCA\n",
        "\n",
        "knn_pipe = Pipeline([('inf_b_gone',RemoveInfs()), ('simp', SimpleImputer()), \n",
        "                     ('scaler', StandardScaler()), ('pca', PCA()), ('knn', KNeighborsClassifier())])\n",
        "knn_pipe.fit(X_train, y_train)\n",
        "\n",
        "tree_pipe = Pipeline([('inf_b_gone',RemoveInfs()), ('simp', SimpleImputer()), \n",
        "                      ('scaler', StandardScaler()), ('pca', PCA()), ('tree', DecisionTreeClassifier())])\n",
        "tree_pipe.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "#************* KNN *************#\n",
        "knn_para = {'simp__strategy':['mean'],\n",
        "            'pca__n_components': ['mle', 20, 50, 100],\n",
        "            'knn__n_neighbors':[1,3,5,7,11],\n",
        "            }\n",
        "\n",
        "knn_gs = GridSearchCV(knn_pipe, knn_para, scoring=\"accuracy\", n_jobs=-1, verbose=10)\n",
        "knn_gs.fit(X_train, y_train)\n",
        "print('|**********KNN**********|\\n', \n",
        "      'Best Params: \\n', knn_gs.best_params_, '\\n',\n",
        "      'Best Score: \\n', knn_gs.best_score_, '\\n',)\n",
        "\n",
        "#************* Tree *************#\n",
        "tree_para = {'simp__strategy':['mean'],\n",
        "             'pca__n_components': ['mle', 20, 50, 100],\n",
        "             'tree__criterion':['gini','entropy'],\n",
        "             'tree__max_depth':[16,32,64],\n",
        "             }\n",
        "\n",
        "tree_gs = GridSearchCV(tree_pipe, tree_para, scoring=\"accuracy\", n_jobs=-1, verbose=10)\n",
        "tree_gs.fit(X_train, y_train)\n",
        "print('|**********Tree**********|\\n', \n",
        "      'Best Params: \\n', tree_gs.best_params_, '\\n',\n",
        "      'Best Score: \\n', tree_gs.best_score_, '\\n',)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmAuc40aoAvF",
        "outputId": "57d8475c-4bb3-4f38-e57d-c047c8bd782d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|**********KNN**********|\n",
            " Best Score: \n",
            " 0.9015544041450777 \n",
            "\n",
            "|**********Tree**********|\n",
            " Best Score: \n",
            " 0.8652849740932642 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#How did these preforme on our holdout test set\n",
        "print('|**********KNN**********|\\n', \n",
        "      'Best Score: \\n', knn_gs.best_estimator_.score(X_test, y_test), '\\n',)\n",
        "\n",
        "print('|**********Tree**********|\\n', \n",
        "      'Best Score: \\n', tree_gs.best_estimator_.score(X_test, y_test), '\\n',)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWlpxBql9GG2"
      },
      "source": [
        "### Observations on Results\n",
        "\n",
        "**K-Nearest Neighbors (KNN):** Scaling the features resulted in a minor improvement in the model's performance.\n",
        "\n",
        "**Decision Tree:** The model's performance decreased, and it is notable that the cross-validation selected the largest available depth. It may be worthwhile to consider increasing the maximum depth, but caution is necessary to avoid overfitting the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYoMg0EZIrNd"
      },
      "source": [
        "## New classifier\n",
        "\n",
        "Replicate the previous task for another classifier. Briefly describe your choice.\n",
        "Try to create the best model for the given dataset.\n",
        "Save your best model into your github. And create a single code cell that loads it and evaluate it on the following test dataset:\n",
        "https://github.com/andvise/DataAnalyticsDatasets/blob/main/dm_assignment2/sat_dataset_test.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-u8BBnP-y3p"
      },
      "source": [
        "### Selection of New Classifiers\n",
        "\n",
        "Two additional classifiers have been chosen for exploration: the Random Forest Classifier and the XGBClassifier, a popular extreme gradient boosting classifier. Both classifiers utilize decision trees but construct them in distinct ways.\n",
        "\n",
        "#### Random Forest\n",
        "A random forest consists of multiple decision trees, each grown independently from one another. The final classification is determined by the majority vote of all the trees in the ensemble. This approach offers improved generalization compared to individual decision trees, as it benefits from the collective wisdom of multiple trees.\n",
        "\n",
        "#### Extreme Gradient Boosting (XGBoost)\n",
        "Gradient boosting, like random forests, also involves an ensemble of decision trees. However, these trees are grown sequentially, with each tree learning from the previous tree to reduce the error via gradient descent along a loss curve. XGBoost incorporates additional optimizations, such as pruning, regularization, and parallel processing, to enhance the model's performance while reducing overfitting and bias.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdSdZdAZB_AT"
      },
      "source": [
        "### Cross-Validation Parameter Selection\n",
        "\n",
        "*Important note:* The GridSearchCV with the chosen parameters requires a significant amount of time due to the number of fits involved. To obtain similar results in less time, consider using RandomizedSearchCV instead.\n",
        "\n",
        "#### Random Forest\n",
        "- **n_estimators:** The number of trees in the forest. Increasing the number of trees generally leads to better performance.\n",
        "- **Criterion:** Both Gini impurity and entropy are evaluated as splitting criteria to identify the best option.\n",
        "- **max_depth:** Maximum tree depth is explored, with a preference for smaller trees to prevent overfitting.\n",
        "\n",
        "#### XGBoost\n",
        "The following parameter sets are searched for XGBoost:\n",
        "\n",
        "- **n_estimators:** The number of trees in the forest. Increasing the number of trees generally leads to better performance.\n",
        "- **eta:** This is the learning rate of the gradient descent. A balanced learning rate is desired to avoid overshooting or undershooting the local minima in the loss curve.\n",
        "- **max_depth:** Maximum tree depth is explored, with a preference for smaller trees to prevent overfitting.\n",
        "\n",
        "*Final note:* No changes were made to the preprocessing or parameter search for these classifiers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRJXrY2hI32F",
        "outputId": "28210882-f57e-4194-ed57-090dbde5df58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "|**********Tree**********|\n",
            " Best Params: \n",
            " {'pca__n_components': 50, 'rf__criterion': 'gini', 'rf__max_depth': 32, 'rf__n_estimators': 1000, 'simp__strategy': 'mean'} \n",
            " Best Score: \n",
            " 0.9488888888888889 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "rf_pipe = Pipeline([('inf_b_gone',RemoveInfs()), ('simp', SimpleImputer()), \n",
        "                    ('scaler', StandardScaler()), ('pca', PCA()), ('rf', RandomForestClassifier())])\n",
        "\n",
        "rf_para = {'simp__strategy':['mean'],\n",
        "           'pca__n_components': ['mle', 20, 50, 100],\n",
        "           'rf__n_estimators':[500, 1000, 2000],\n",
        "           'rf__criterion':['gini','entropy'],\n",
        "           'rf__max_depth':[8, 16, 32, 64],\n",
        "            }\n",
        "\n",
        "rf_gs = GridSearchCV(rf_pipe, rf_para, scoring=\"accuracy\", n_jobs=-1, verbose=10)\n",
        "rf_gs.fit(X_train, y_train)\n",
        "print('|**********Tree**********|\\n', \n",
        "      'Best Params: \\n', rf_gs.best_params_, '\\n',\n",
        "      'Best Score: \\n', rf_gs.best_score_, '\\n',)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgqMz7neEBSn",
        "outputId": "eb7083dc-8f1b-4e20-b16f-223df0693d98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
            "|**********XGBM**********|\n",
            " Best Params: \n",
            " {'pca__n_components': 'mle', 'simp__strategy': 'mean', 'xgbm__eta': 0.1, 'xgbm__max_depth': 8, 'xgbm__n_estimators': 2000} \n",
            " Best Score: \n",
            " 0.9540740740740741 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "xgbm_pipe = Pipeline([('inf_b_gone',RemoveInfs()), ('simp', SimpleImputer()), \n",
        "                    ('scaler', StandardScaler()), ('pca', PCA()), ('xgbm', XGBClassifier())])\n",
        "\n",
        "xgbm_para = {'simp__strategy':['mean'],\n",
        "            'pca__n_components': ['mle', 20, 50, 100],\n",
        "            'xgbm__n_estimators':[500,1000,2000],\n",
        "            'xgbm__max_depth':[8, 16, 32, 64],\n",
        "            'xgbm__eta':[0.1,0.3,0.5] #test different learning rates to try to avoid local minima\n",
        "            }\n",
        "\n",
        "xgbm_gs = GridSearchCV(xgbm_pipe,xgbm_para, scoring=\"accuracy\", n_jobs=-1, verbose=10)\n",
        "xgbm_gs.fit(X_train, y_train)\n",
        "\n",
        "print('|**********XGBM**********|\\n', \n",
        "      'Best Params: \\n', xgbm_gs.best_params_, '\\n',\n",
        "      'Best Score: \\n', xgbm_gs.best_score_, '\\n',)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5K5GLdJJoe4x",
        "outputId": "70ad8692-a782-4d19-b7c0-4916124fa54e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|**********Random Forest**********|\n",
            " Best Score: \n",
            " 0.924006908462867 \n",
            "\n",
            "|**********XGBM**********|\n",
            " Best Score: \n",
            " 0.9481865284974094 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#How did these preforme on our holdout test set\n",
        "print('|**********Random Forest**********|\\n', \n",
        "      'Best Score: \\n', rf_gs.best_estimator_.score(X_test, y_test), '\\n',)\n",
        "\n",
        "print('|**********XGBM**********|\\n', \n",
        "      'Best Score: \\n', xgbm_gs.best_estimator_.score(X_test, y_test), '\\n',)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFhMXYWG49OR",
        "outputId": "b761fb2f-5d69-4613-96e9-9bc73003bec2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|**********KNN GS**********|\n",
            " Best Score: \n",
            " 0.979296066252588 \n",
            "\n",
            "|*********Tree GS**********|\n",
            " Best Score: \n",
            " 0.9606625258799172 \n",
            "\n",
            "|**********Ransom Forest GS**********|\n",
            " Best Score: \n",
            " 0.9875776397515528 \n",
            "\n",
            "|**********XGBM GS**********|\n",
            " Best Score: \n",
            " 0.9937888198757764 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_test = pd.read_csv('https://github.com/andvise/DataAnalyticsDatasets/blob/f4c1e07915ddfe98f0f5434ec3f0e7f3900f35ab/dm_assignment2/sat_dataset_test.csv?raw=True')\n",
        "\n",
        "X_valid, y_valid = df_test[features], df_test[labels]\n",
        "\n",
        "print('|**********KNN GS**********|\\n', \n",
        "      'Best Score: \\n', knn_gs.best_estimator_.score(X_valid, y_valid), '\\n',)\n",
        "\n",
        "print('|*********Tree GS**********|\\n', \n",
        "      'Best Score: \\n', tree_gs.best_estimator_.score(X_valid, y_valid), '\\n',)\n",
        "\n",
        "print('|**********Ransom Forest GS**********|\\n', \n",
        "      'Best Score: \\n', rf_gs.best_estimator_.score(X_valid, y_valid), '\\n',)\n",
        "\n",
        "print('|**********XGBM GS**********|\\n', \n",
        "      'Best Score: \\n', xgbm_gs.best_estimator_.score(X_valid, y_valid), '\\n',)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations on Results\n",
        "\n",
        "Among the four classifiers explored, XGBoost demonstrated the best performance. As the test and training scores are closely aligned and XGBoost incorporates techniques to reduce overfitting, this model is chosen as the most suitable for the given task."
      ],
      "metadata": {
        "id": "i2esM8K0Meif"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8NCjIbbxAH-",
        "outputId": "0f505253-7417-4ae4-ff3d-dd03d11d4559"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['bestmodel.joblib']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from joblib import dump, load\n",
        "dump(xgbm_gs.best_estimator_, 'bestmodel.joblib')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}